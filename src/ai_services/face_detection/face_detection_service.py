# cSpell:disable
# mypy: ignore-errors
"""
‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (Enhanced Intelligent Face Detection Service) ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv9c, YOLOv9e ‡πÅ‡∏•‡∏∞ YOLOv11m
‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ä‡πâ 4 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
"""
import time
import logging
import cv2
import numpy as np
import os
from typing import Dict, List, Tuple, Any, Optional, Union
from enum import Enum

from .yolo_models import YOLOv9ONNXDetector, YOLOv11Detector
from .utils import BoundingBox, FaceDetection, DetectionResult, calculate_face_quality

# ‡πÑ‡∏°‡πà import VRAMManager ‡πÅ‡∏ï‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á stub class ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÅ‡∏ó‡∏ô
class VRAMManager:
    """Stub class for VRAMManager."""
    async def request_model_allocation(self, *args, **kwargs):
        class Allocation:
            class Location:
                value = "cpu"
            location = Location()
        return Allocation()
    
    async def release_model_allocation(self, *args, **kwargs):
        return True
        
    async def get_vram_status(self, *args, **kwargs):
        return {"status": "stub", "available": 0}

logger = logging.getLogger(__name__)


class QualityCategory(Enum):
    """‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
    EXCELLENT = "excellent"  # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° (80-100)
    GOOD = "good"            # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ (70-79)
    ACCEPTABLE = "acceptable"  # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏û‡∏≠‡πÉ‡∏ä‡πâ (60-69)
    POOR = "poor"            # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥ (<60)


class FaceQualityAnalyzer:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        
        Args:
            config: ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        """
        # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Å‡∏ì‡∏ë‡πå
        self.quality_weights = {
            'size_weight': config.get('size_weight', 40),
            'area_weight': config.get('area_weight', 30),
            'confidence_weight': config.get('confidence_weight', 20),
            'aspect_weight': config.get('aspect_weight', 10)
        }
        
        # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏ô‡∏≤‡∏î
        self.size_thresholds = {
            'excellent': config.get('excellent_size', (100, 100)),
            'good': config.get('good_size', (64, 64)),
            'acceptable': config.get('acceptable_size', (32, 32)),
            'minimum': config.get('minimum_size', (16, 16))
        }
        
        # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
        self.min_quality_threshold = config.get('min_quality_threshold', 60)
    
    def get_quality_category(self, score: float) -> QualityCategory:
        """‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô"""
        if score >= 80:
            return QualityCategory.EXCELLENT
        elif score >= 70:
            return QualityCategory.GOOD
        elif score >= 60:
            return QualityCategory.ACCEPTABLE
        else:
            return QualityCategory.POOR
    
    def is_face_usable(self, face: FaceDetection) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        if face.quality_score is None:
            return False
        return face.quality_score >= self.min_quality_threshold
    
    def analyze_detection_quality(self, faces: List[FaceDetection]) -> Dict[str, Any]:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        
        Args:
            faces: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
        """
        if not faces:
            return {
                'total_count': 0,
                'usable_count': 0,
                'quality_ratio': 0.0,
                'quality_categories': {
                    'excellent': 0,
                    'good': 0,
                    'acceptable': 0,
                    'poor': 0
                },
                'avg_quality': 0.0
            }
        
        # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        quality_categories = {
            'excellent': 0,
            'good': 0,
            'acceptable': 0,
            'poor': 0
        }
        
        usable_count = 0
        quality_scores = []
        
        for face in faces:
            if face.quality_score is not None:
                quality_scores.append(face.quality_score)
                category = self.get_quality_category(face.quality_score)
                quality_categories[category.value] += 1
                
                if self.is_face_usable(face):
                    usable_count += 1
        
        total_count = len(faces)
        quality_ratio = (usable_count / total_count) * 100 if total_count > 0 else 0
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        
        return {
            'total_count': total_count,
            'usable_count': usable_count,
            'quality_ratio': quality_ratio,
            'quality_categories': quality_categories,
            'avg_quality': avg_quality
        }


class DecisionResult:
    """‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    
    def __init__(self):
        # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö YOLOv9
        self.yolov9c_detections = []
        self.yolov9e_detections = []
        self.yolov9c_time = 0.0
        self.yolov9e_time = 0.0
        
        # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢
        self.agreement = False
        self.agreement_ratio = 0.0
        self.agreement_type = ""
        
        # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        self.use_yolov11m = False
        self.decision_reasons = []
        
        # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        self.final_detections = []
        self.final_model = ""
        self.final_time = 0.0
        
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        self.quality_info = {}
        
        # ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        self.total_time = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JSON"""
        return {
            'step1_results': {
                'yolov9c': {
                    'count': len(self.yolov9c_detections),
                    'time': self.yolov9c_time
                },
                'yolov9e': {
                    'count': len(self.yolov9e_detections),
                    'time': self.yolov9e_time
                }
            },
            'step2_agreement': {
                'agreement': self.agreement,
                'ratio': self.agreement_ratio,
                'type': self.agreement_type
            },
            'step3_decision': {
                'use_yolov11m': self.use_yolov11m,
                'reasons': self.decision_reasons
            },
            'step4_results': {
                'model_used': self.final_model,
                'count': len(self.final_detections),
                'time': self.final_time
            },
            'quality_info': self.quality_info,
            'total_time': self.total_time
        }


class FaceDetectionService:
    """
    ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv9c, YOLOv9e ‡πÅ‡∏•‡∏∞ YOLOv11m
    """
    def __init__(self, vram_manager: VRAMManager, config: Dict[str, Any]):
        """
        ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        
        Args:
            vram_manager: ‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ GPU
            config: ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£
        """
        self.vram_manager = vram_manager
        self.config = config
        self.models: dict[str, Union[YOLOv9ONNXDetector, YOLOv11Detector]] = {}
        self.model_stats: dict[str, dict[str, Union[float, int]]] = {}
        
        # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        self.decision_criteria = {
            'max_usable_faces_yolov9': int(config.get('max_usable_faces_yolov9', 8)),
            'min_agreement_ratio': float(config.get('min_agreement_ratio', 0.7)),
            'min_quality_threshold': int(config.get('min_quality_threshold', 60)),
            'iou_threshold': float(config.get('iou_threshold', 0.5))
        }
        
        # ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
        self.detection_params = {
            'conf_threshold': config.get('conf_threshold', 0.15),
            'iou_threshold': config.get('iou_threshold', 0.4),
            'img_size': config.get('img_size', 640)
        }
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        self.quality_analyzer = FaceQualityAnalyzer({
            'min_quality_threshold': self.decision_criteria['min_quality_threshold'],
            'size_weight': config.get('size_weight', 40),
            'area_weight': config.get('area_weight', 30),
            'confidence_weight': config.get('confidence_weight', 20),
            'aspect_weight': config.get('aspect_weight', 10)
        })
        
        self.yolov9c_model_path = config.get('yolov9c_model_path', 'model/face-detection/yolov9c-face-lindevs.onnx')
        self.yolov9e_model_path = config.get('yolov9e_model_path', 'model/face-detection/yolov9e-face-lindevs.onnx')
        self.yolov11m_model_path = config.get('yolov11m_model_path', 'model/face-detection/yolov11m-face.pt')
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        self.decision_log = []
        
        self.models_loaded = False
    
    async def initialize(self) -> bool:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        
        Returns:
            ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
        """
        try:
            logger.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î...")
            
            # ‡∏Ç‡∏≠‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£ VRAM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv9c
            yolov9c_allocation = await self.vram_manager.request_model_allocation(
                "yolov9c-face", "high", "face_detection_service"
            )
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv9c
            self.models['yolov9c'] = YOLOv9ONNXDetector(self.yolov9c_model_path, "YOLOv9c")
            yolov9c_device = "cuda" if yolov9c_allocation.location.value == "gpu" else "cpu"
            self.models['yolov9c'].load_model(yolov9c_device)
            
            # ‡∏Ç‡∏≠‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£ VRAM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv9e
            yolov9e_allocation = await self.vram_manager.request_model_allocation(
                "yolov9e-face", "high", "face_detection_service"
            )
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv9e
            self.models['yolov9e'] = YOLOv9ONNXDetector(self.yolov9e_model_path, "YOLOv9e")
            yolov9e_device = "cuda" if yolov9e_allocation.location.value == "gpu" else "cpu"
            self.models['yolov9e'].load_model(yolov9e_device)
            
            # ‡∏Ç‡∏≠‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£ VRAM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv11m
            yolov11m_allocation = await self.vram_manager.request_model_allocation(
                "yolov11m-face", "critical", "face_detection_service"
            )
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv11m
            self.models['yolov11m'] = YOLOv11Detector(self.yolov11m_model_path, "YOLOv11m")
            yolov11m_device = "cuda" if yolov11m_allocation.location.value == "gpu" else "cpu"
            self.models['yolov11m'].load_model(yolov11m_device)
            
            self.models_loaded = True
            logger.info("‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            return True
            
        except Exception as e:
            logger.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
            return False
    
    async def detect_faces(self, 
                         image_input: Union[str, np.ndarray],
                         model_name: Optional[str] = None,
                         conf_threshold: Optional[float] = None,
                         iou_threshold: Optional[float] = None,
                         enhanced_mode: bool = True) -> DetectionResult:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        
        Args:
            image_input: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠ numpy array
            model_name: ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ ('yolov9c', 'yolov9e', 'yolov11m' ‡∏´‡∏£‡∏∑‡∏≠ 'auto')
            conf_threshold: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
            iou_threshold: ‡∏Ñ‡πà‡∏≤ IoU threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NMS
            enhanced_mode: ‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î Enhanced Intelligent Detection ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        """
        if not self.models_loaded:
            raise RuntimeError("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏Å initialize() ‡∏Å‡πà‡∏≠‡∏ô")
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
        conf_threshold = conf_threshold or self.detection_params['conf_threshold']
        iou_threshold = iou_threshold or self.detection_params['iou_threshold']
        
        start_time = time.time()
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        if isinstance(image_input, str):
            if not os.path.exists(image_input):
                raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {image_input}")
            image = cv2.imread(image_input)
            if image is None:
                raise ValueError(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ: {image_input}")
        else:
            image = image_input
        
        # ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏±‡πâ‡∏ô
        if model_name in ['yolov9c', 'yolov9e', 'yolov11m']:
            logger.info(f"‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_name} ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏")
            detections = self._detect_with_model(
                image, model_name, conf_threshold, iou_threshold
            )
            return self._create_result(detections, image.shape, time.time() - start_time, model_name)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        if enhanced_mode:
            logger.info("‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ Enhanced Intelligent Detection")
            return await self.enhanced_intelligent_detect(image, conf_threshold, iou_threshold, start_time)
        else:
            logger.info("‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô")
            return await self._intelligent_detect(image, conf_threshold, iou_threshold, start_time)
    
    def _detect_with_model(self, 
                         image: np.ndarray, 
                         model_name: str,
                         conf_threshold: float,
                         iou_threshold: float) -> List[FaceDetection]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
        
        Args:
            image: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (numpy array)
            model_name: ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• ('yolov9c', 'yolov9e', 'yolov11m')
            conf_threshold: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
            iou_threshold: ‡∏Ñ‡πà‡∏≤ IoU threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NMS
        
        Returns:
            ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
        """
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        model_start_time = time.time()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        detections_raw = self.models[model_name].detect(
            image, conf_threshold, iou_threshold
        )
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
        inference_time = time.time() - model_start_time
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        face_detections = []
        for det in detections_raw:
            bbox = BoundingBox.from_array(det)
            # ‡πÅ‡∏õ‡∏•‡∏á image.shape[:2] ‡πÄ‡∏õ‡πá‡∏ô tuple[int, int] ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö signature ‡∏Ç‡∏≠‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
            image_size = (int(image.shape[0]), int(image.shape[1]))
            quality_score = calculate_face_quality(bbox, image_size)
            
            face = FaceDetection(
                bbox=bbox,
                quality_score=quality_score,
                model_used=model_name,
                processing_time=inference_time
            )
            face_detections.append(face)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        quality_scores = [f.quality_score for f in face_detections if f.quality_score is not None]
        self.model_stats[model_name] = {
            'last_inference_time': inference_time,
            'face_count': len(face_detections),
            'avg_quality': float(np.mean(quality_scores)) if quality_scores else 0.0
        }
        
        return face_detections
    
    async def _intelligent_detect(self,
                               image: np.ndarray,
                               conf_threshold: float,
                               iou_threshold: float,
                               start_time: float) -> DetectionResult:
        """
        ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        
        Args:
            image: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (numpy array)
            conf_threshold: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
            iou_threshold: ‡∏Ñ‡πà‡∏≤ IoU threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NMS
            start_time: ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        """
        logger.debug("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞...")
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 1: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9c ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        yolov9c_detections = self._detect_with_model(
            image, 'yolov9c', conf_threshold, iou_threshold
        )
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡∏¢ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ YOLOv11m ‡∏ã‡∏∂‡πà‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏Å‡∏ß‡πà‡∏≤
        if not yolov9c_detections:
            logger.debug("YOLOv9c ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ YOLOv11m...")
            yolov11m_detections = self._detect_with_model(
                image, 'yolov11m', conf_threshold, iou_threshold
            )
            return self._create_result(
                yolov11m_detections, image.shape, time.time() - start_time, 'yolov11m'
            )
        
        # ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ YOLOv9c ‡πÄ‡∏•‡∏¢
        max_faces = self.decision_criteria['max_usable_faces_yolov9']
        if len(yolov9c_detections) <= max_faces:
            logger.debug(f"YOLOv9c ‡∏û‡∏ö {len(yolov9c_detections)} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‚â§{max_faces}) ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢")
            return self._create_result(
                yolov9c_detections, image.shape, time.time() - start_time, 'yolov9c'
            )
        
        # ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9e ‡∏ï‡πà‡∏≠
        logger.debug(f"YOLOv9c ‡∏û‡∏ö {len(yolov9c_detections)} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (>{max_faces}) ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9e...")
        yolov9e_detections = self._detect_with_model(
            image, 'yolov9e', conf_threshold, iou_threshold
        )
        
        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á YOLOv9c ‡πÅ‡∏•‡∏∞ YOLOv9e
        agreement = self._calculate_agreement(
            yolov9c_detections, yolov9e_detections, self.decision_criteria['iou_threshold']
        )
        
        # ‡∏ñ‡πâ‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ YOLOv9e
        min_agreement = self.decision_criteria['min_agreement_ratio']
        if agreement >= min_agreement:
            logger.debug(f"YOLOv9c ‡πÅ‡∏•‡∏∞ YOLOv9e ‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô {agreement:.1%} (‚â•{min_agreement:.1%}) ‡πÉ‡∏ä‡πâ YOLOv9e")
            return self._create_result(
                yolov9e_detections, image.shape, time.time() - start_time, 'yolov9e'
            )
        
        # ‡∏ñ‡πâ‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ YOLOv11m ‡∏ã‡∏∂‡πà‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        logger.debug(f"YOLOv9c ‡πÅ‡∏•‡∏∞ YOLOv9e ‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á {agreement:.1%} (<{min_agreement:.1%}) ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ YOLOv11m...")
        yolov11m_detections = self._detect_with_model(
            image, 'yolov11m', conf_threshold, iou_threshold
        )
        
        return self._create_result(
            yolov11m_detections, image.shape, time.time() - start_time, 'yolov11m'
        )
    
    def _calculate_agreement(self, 
                          detections1: List[FaceDetection], 
                          detections2: List[FaceDetection],
                          iou_threshold: float) -> float:
        """
        ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏≠‡∏á‡∏ä‡∏∏‡∏î
        
        Args:
            detections1: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 1
            detections2: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 2
            iou_threshold: ‡∏Ñ‡πà‡∏≤ IoU threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
            
        Returns:
            ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á (0.0-1.0)
        """
        if not detections1 or not detections2:
            return 0.0
        
        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        total_faces = max(len(detections1), len(detections2))
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å
        boxes1 = np.array([d.bbox.to_array()[:4] for d in detections1])  # x1, y1, x2, y2
        boxes2 = np.array([d.bbox.to_array()[:4] for d in detections2])  # x1, y1, x2, y2
        
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
        matched_count = 0
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡πÅ‡∏£‡∏Å
        for box1 in boxes1:
            best_iou = 0.0
            
            # ‡∏´‡∏≤ IoU ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á
            for i, box2 in enumerate(boxes2):
                iou = self._calculate_iou(box1, box2)
                if iou > best_iou:
                    best_iou = iou
            
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ IoU ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏û‡∏≠ ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
            if best_iou >= iou_threshold:
                matched_count += 1
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô
        return matched_count / total_faces
    
    def _calculate_iou(self, box1: np.ndarray, box2: np.ndarray) -> float:
        """
        ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ IoU (Intersection over Union) ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á
        
        Args:
            box1: ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 1 [x1, y1, x2, y2]
            box2: ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 2 [x1, y1, x2, y2]
            
        Returns:
            ‡∏Ñ‡πà‡∏≤ IoU (0.0-1.0)
        """
        # ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
        x_left = max(box1[0], box2[0])
        y_top = max(box1[1], box2[1])
        x_right = min(box1[2], box2[2])
        y_bottom = min(box1[3], box2[3])
        
        if x_right < x_left or y_bottom < y_top:
            return 0.0
        
        intersection_area = (x_right - x_left) * (y_bottom - y_top)
        
        # ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡πà‡∏≠‡∏á
        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
          # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì IoU
        iou = intersection_area / float(box1_area + box2_area - intersection_area)
        
        return iou
        
    def _create_result(self, 
                     detections: List[FaceDetection], 
                     image_shape: Tuple[int, ...],
                     total_time: float,
                     model_used: str) -> DetectionResult:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
        
        Args:
            detections: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
            image_shape: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (height, width, channels)
            total_time: ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            model_used: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
            
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        """
        # ‡πÅ‡∏õ‡∏•‡∏á image_shape ‡πÄ‡∏õ‡πá‡∏ô Tuple[int, int, int]
        shape = (image_shape[0], image_shape[1], image_shape[2] if len(image_shape) > 2 else 3)
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        quality_info = self.quality_analyzer.analyze_detection_quality(detections)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        result = DetectionResult(
            faces=detections,
            image_shape=shape,
            total_processing_time=total_time,
            model_used=model_used,
            fallback_used=False
        )
          # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        result.quality_info = quality_info
        
        return result
        
    async def get_service_info(self) -> Dict[str, Any]:
        """
        ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        """
        vram_status = await self.vram_manager.get_vram_status()
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        decision_stats = {}
        if self.decision_log:
            # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            decision_stats["total_decisions"] = len(self.decision_log)
            
            # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
            model_counts = {"yolov9c": 0, "yolov9e": 0, "yolov11m": 0}
            for decision in self.decision_log:
                model_used = decision["step4_results"]["model_used"]
                model_counts[model_used] = model_counts.get(model_used, 0) + 1
            
            decision_stats["model_usage"] = model_counts
            
            # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢
            agreement_counts = {"high_overlap": 0, "low_overlap": 0}
            for decision in self.decision_log:
                agreement_type = decision["step2_agreement"]["type"]
                agreement_counts[agreement_type] = agreement_counts.get(agreement_type, 0) + 1
            
            decision_stats["agreement_stats"] = agreement_counts
            
            # ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÉ‡∏ä‡πâ YOLOv11m
            yolov11m_reasons = {}
            for decision in self.decision_log:
                if decision["step3_decision"]["use_yolov11m"]:
                    for reason in decision["step3_decision"]["reasons"]:
                        yolov11m_reasons[reason] = yolov11m_reasons.get(reason, 0) + 1
            
            decision_stats["yolov11m_reasons"] = yolov11m_reasons
            
            # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
            quality_stats = {
                "total_faces": 0,
                "usable_faces": 0,
                "avg_quality_ratio": 0.0
            }
            
            for decision in self.decision_log:
                if "quality_info" in decision:
                    quality_stats["total_faces"] += decision["quality_info"].get("total_count", 0)
                    quality_stats["usable_faces"] += decision["quality_info"].get("usable_count", 0)
            
            if quality_stats["total_faces"] > 0:
                quality_stats["avg_quality_ratio"] = quality_stats["usable_faces"] / quality_stats["total_faces"] * 100
            
            decision_stats["quality_stats"] = quality_stats
        
        return {
            "service_name": "Enhanced Intelligent Face Detection Service",
            "models_loaded": self.models_loaded,
            "available_models": list(self.models.keys()),
            "model_stats": self.model_stats,
            "decision_criteria": self.decision_criteria,
            "detection_params": self.detection_params,
            "vram_status": vram_status,
            "decision_stats": decision_stats,
            "recent_decisions": self.decision_log[-5:] if self.decision_log else []
        }
    
    async def cleanup(self) -> bool:
        """
        ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£
        
        Returns:
            ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
        """
        try:
            # ‡∏Ñ‡∏∑‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£ VRAM
            await self.vram_manager.release_model_allocation("yolov9c-face")
            await self.vram_manager.release_model_allocation("yolov9e-face")
            await self.vram_manager.release_model_allocation("yolov11m-face")
            
            # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•
            self.models = {}
            self.models_loaded = False
            
            logger.info("‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            return True
            
        except Exception as e:
            logger.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£: {e}")
            return False
    
    async def enhanced_intelligent_detect(self,
                                 image: np.ndarray,
                                 conf_threshold: float,
                                 iou_threshold: float,
                                 start_time: float) -> DetectionResult:
        """
        ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ 4 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        1. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9 (YOLOv9c + YOLOv9e)
        2. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Agreement Analysis)
        3. ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Decision Logic)
        4. ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        
        Args:
            image: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (numpy array)
            conf_threshold: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
            iou_threshold: ‡∏Ñ‡πà‡∏≤ IoU threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NMS
            start_time: ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        """
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        decision_result = DecisionResult()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        decision_result.total_time = time.time() - start_time
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9c ‡πÅ‡∏•‡∏∞ YOLOv9e
        logger.info("üìä Step 1: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9 models...")
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9c
        yolov9c_start_time = time.time()
        yolov9c_detections = self._detect_with_model(
            image, 'yolov9c', conf_threshold, iou_threshold
        )
        yolov9c_time = time.time() - yolov9c_start_time
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        decision_result.yolov9c_detections = yolov9c_detections
        decision_result.yolov9c_time = yolov9c_time
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û YOLOv9c
        yolov9c_quality = self.quality_analyzer.analyze_detection_quality(yolov9c_detections)
        logger.info(f"üîπ YOLOv9c: {yolov9c_quality['total_count']} total, {yolov9c_quality['usable_count']} usable ({yolov9c_time:.2f}s)")
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡∏¢ ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4 ‡πÄ‡∏•‡∏¢ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ YOLOv11m
        if not yolov9c_detections:
            decision_result.use_yolov11m = True
            decision_result.decision_reasons.append("No faces detected by YOLOv9c")
            return await self._finish_enhanced_detection(decision_result, image, conf_threshold, iou_threshold, start_time)
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv9e
        yolov9e_start_time = time.time()
        yolov9e_detections = self._detect_with_model(
            image, 'yolov9e', conf_threshold, iou_threshold
        )
        yolov9e_time = time.time() - yolov9e_start_time
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        decision_result.yolov9e_detections = yolov9e_detections
        decision_result.yolov9e_time = yolov9e_time
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û YOLOv9e
        yolov9e_quality = self.quality_analyzer.analyze_detection_quality(yolov9e_detections)
        logger.info(f"üîπ YOLOv9e: {yolov9e_quality['total_count']} total, {yolov9e_quality['usable_count']} usable ({yolov9e_time:.2f}s)")
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Agreement Analysis)
        logger.info("üìä Step 2: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á YOLOv9 models...")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢
        agreement_ratio = self._calculate_agreement(
            yolov9c_detections, yolov9e_detections, self.decision_criteria['iou_threshold']
        )
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢
        agreement = agreement_ratio >= self.decision_criteria['min_agreement_ratio']
        agreement_type = "high_overlap" if agreement else "low_overlap"
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        decision_result.agreement = agreement
        decision_result.agreement_ratio = agreement_ratio
        decision_result.agreement_type = agreement_type
        
        logger.info(f"üîπ Agreement: {agreement} ({agreement_type})")
        logger.info(f"üîπ Agreement ratio: {agreement_ratio:.2f}")
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Decision Logic)
        logger.info("üéØ Step 3: ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
        
        # ‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
        max_usable_faces = max(yolov9c_quality['usable_count'], yolov9e_quality['usable_count'])
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        use_yolov11m = False
        reasons = []
        
        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ YOLOv11m
        if not agreement:
            use_yolov11m = True
            reasons.append("YOLOv9 models disagree")
        elif max_usable_faces > self.decision_criteria['max_usable_faces_yolov9']:
            use_yolov11m = True
            reasons.append(f"Too many faces ({max_usable_faces} > {self.decision_criteria['max_usable_faces_yolov9']})")
        elif max_usable_faces == 0:
            use_yolov11m = True
            reasons.append("No usable faces from YOLOv9")
        else:
            reasons.append(f"YOLOv9 sufficient: {max_usable_faces} usable faces")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        decision_result.use_yolov11m = use_yolov11m
        decision_result.decision_reasons = reasons
        
        logger.info(f"üîπ Use YOLOv11m: {use_yolov11m}")
        for reason in reasons:
            logger.info(f"üîπ Reason: {reason}")
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        return await self._finish_enhanced_detection(decision_result, image, conf_threshold, iou_threshold, start_time)
    
    async def _finish_enhanced_detection(self,
                                       decision_result: DecisionResult,
                                       image: np.ndarray,
                                       conf_threshold: float,
                                       iou_threshold: float,
                                       start_time: float) -> DetectionResult:
        """
        ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        
        Args:
            decision_result: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
            image: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (numpy array)
            conf_threshold: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
            iou_threshold: ‡∏Ñ‡πà‡∏≤ IoU threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NMS
            start_time: ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        """
        logger.info("üìä Step 4: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å...")
        
        # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ YOLOv11m
        if decision_result.use_yolov11m:
            logger.info("üîπ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLOv11m...")
            yolov11m_start_time = time.time()
            yolov11m_detections = self._detect_with_model(
                image, 'yolov11m', conf_threshold, iou_threshold
            )
            yolov11m_time = time.time() - yolov11m_start_time
            
            final_detections = yolov11m_detections
            final_model = 'yolov11m'
            final_time = yolov11m_time
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
            quality_info = self.quality_analyzer.analyze_detection_quality(final_detections)
            logger.info(f"üîπ YOLOv11m: {quality_info['total_count']} total, {quality_info['usable_count']} usable ({final_time:.2f}s)")
        else:
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv9 ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÄ‡∏≠‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤)
            yolov9c_quality = self.quality_analyzer.analyze_detection_quality(decision_result.yolov9c_detections)
            yolov9e_quality = self.quality_analyzer.analyze_detection_quality(decision_result.yolov9e_detections)
            
            if yolov9e_quality['usable_count'] >= yolov9c_quality['usable_count']:
                logger.info("üîπ ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å YOLOv9e")
                final_detections = decision_result.yolov9e_detections
                final_model = 'yolov9e'
                final_time = decision_result.yolov9e_time
                quality_info = yolov9e_quality
            else:
                logger.info("üîπ ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å YOLOv9c")
                final_detections = decision_result.yolov9c_detections
                final_model = 'yolov9c'
                final_time = decision_result.yolov9c_time
                quality_info = yolov9c_quality
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        decision_result.final_detections = final_detections
        decision_result.final_model = final_model
        decision_result.final_time = final_time
        decision_result.quality_info = quality_info
        decision_result.total_time = time.time() - start_time
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å decision log
        self.decision_log.append(decision_result.to_dict())
        
        # ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        logger.info("‚úÖ Results:")
        logger.info(f"üîπ Model used: {final_model}")
        logger.info(f"üîπ Total faces: {quality_info['total_count']}")
        logger.info(f"üîπ Usable faces: {quality_info['usable_count']}")
        logger.info(f"üîπ Quality ratio: {quality_info['quality_ratio']:.1f}%")
        logger.info(f"üîπ Processing time: {final_time:.2f}s")
        logger.info(f"üîπ Total time: {decision_result.total_time:.2f}s")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        return self._create_result(
            final_detections, image.shape, decision_result.total_time, final_model
        )
