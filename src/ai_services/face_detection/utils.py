# cSpell:disable
"""
‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
"""
import cv2
import numpy as np
import os
import logging
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class BoundingBox:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    """
    x1: float
    y1: float
    x2: float
    y2: float
    confidence: float
    class_id: Optional[int] = None  # MODIFIED: Added class_id
    
    @property
    def width(self) -> float:
        return self.x2 - self.x1
    
    @property
    def height(self) -> float:
        return self.y2 - self.y1
    
    @property
    def area(self) -> float:
        return self.width * self.height
    
    @property
    def center(self) -> Tuple[float, float]:
        return ((self.x1 + self.x2) / 2, (self.y1 + self.y2) / 2)
    
    @property
    def aspect_ratio(self) -> float:
        return self.width / max(self.height, 1e-5)
    
    def to_array(self) -> np.ndarray:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array"""
        return np.array([self.x1, self.y1, self.x2, self.y2, self.confidence])
    
    @classmethod
    def from_array(cls, arr: np.ndarray) -> 'BoundingBox':
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å numpy array"""
        return cls(arr[0], arr[1], arr[2], arr[3], arr[4])


@dataclass
class FaceDetection:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
    """
    bbox: BoundingBox
    quality_score: Optional[float] = None
    model_used: str = ""
    processing_time: float = 0.0
    landmarks: Optional[np.ndarray] = None  # e.g., 5 keypoints (x,y)
    embedding: Optional[np.ndarray] = None # Face embedding vector
    meta: Optional[Dict[str, Any]] = None # Additional metadata
    
    def to_dict(self) -> Dict[str, Any]:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JSON"""
        return {
            "bbox": {
                "x1": float(self.bbox.x1),
                "y1": float(self.bbox.y1),
                "x2": float(self.bbox.x2),
                "y2": float(self.bbox.y2),
                "confidence": float(self.bbox.confidence),
                "width": float(self.bbox.width),
                "height": float(self.bbox.height),
                "center_x": float(self.bbox.center[0]),
                "center_y": float(self.bbox.center[1]),
                "area": float(self.bbox.area),
                "aspect_ratio": float(self.bbox.aspect_ratio)
            },
            "quality_score": self.quality_score,
            "model_used": self.model_used,
            "processing_time": self.processing_time
        }


@dataclass
class DetectionResult:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    """
    faces: List[FaceDetection]
    image_shape: Tuple[int, int, int]
    total_processing_time: float
    model_used: str
    fallback_used: bool = False
    error: Optional[str] = None
    model_processing_time: Optional[float] = None # MODIFIED: Added model_processing_time
    
    def to_dict(self) -> Dict[str, Any]:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JSON"""
        return {
            "faces": [face.to_dict() for face in self.faces],
            "image_shape": {
                "height": self.image_shape[0],
                "width": self.image_shape[1],
                "channels": self.image_shape[2] if len(self.image_shape) > 2 else 1
            },
            "total_processing_time": self.total_processing_time,
            "face_count": len(self.faces),
            "model_used": self.model_used,
            "fallback_used": self.fallback_used,
            "error": self.error
        }


def calculate_face_quality(detection: BoundingBox, image_shape: Tuple[int, int]) -> float:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ - RELAXED VERSION
    
    Args:
        detection: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• BoundingBox ‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        image_shape: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (height, width)
    
    Returns:
        ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û 0-100 (‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô)
    """
    # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Å‡∏ì‡∏ë‡πå (‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î)
    weights = {
        'size_weight': 30,        # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 40
        'area_weight': 25,        # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 30  
        'confidence_weight': 30,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 20
        'aspect_weight': 15       # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 10
    }
    
    # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏ô‡∏≤‡∏î (‡∏´‡∏•‡∏ß‡∏°‡∏Ç‡∏∂‡πâ‡∏ô)
    size_thresholds = {
        'excellent': (80, 80),    # ‡∏•‡∏î‡∏à‡∏≤‡∏Å (100, 100)
        'good': (50, 50),         # ‡∏•‡∏î‡∏à‡∏≤‡∏Å (64, 64)
        'acceptable': (25, 25),   # ‡∏•‡∏î‡∏à‡∏≤‡∏Å (32, 32)
        'minimum': (10, 10)       # ‡∏•‡∏î‡∏à‡∏≤‡∏Å (16, 16)
    }
    
    # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î (‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô)
    face_width = detection.width
    face_height = detection.height
    
    size_score = 0
    if face_width >= size_thresholds['excellent'][0] and face_height >= size_thresholds['excellent'][1]:
        size_score = 100
    elif face_width >= size_thresholds['good'][0] and face_height >= size_thresholds['good'][1]:
        size_score = 85  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 80
    elif face_width >= size_thresholds['acceptable'][0] and face_height >= size_thresholds['acceptable'][1]:
        size_score = 65  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 50
    elif face_width >= size_thresholds['minimum'][0] and face_height >= size_thresholds['minimum'][1]:
        size_score = 45  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 30
    else:
        size_score = 25  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 10
    
    # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏°‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô)
    image_area = image_shape[0] * image_shape[1]
    face_area = detection.area
    area_ratio = min(face_area / image_area * 100, 100)
    
    area_score = 0
    if area_ratio > 20:      # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 30
        area_score = 100
    elif area_ratio > 10:    # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 15
        area_score = 90
    elif area_ratio > 3:     # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 5
        area_score = 80      # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 75
    elif area_ratio > 0.5:   # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 1
        area_score = 60      # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 50
    else:
        area_score = 40      # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 25
    
    # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
    confidence_score = detection.confidence * 100
    
    # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô (‡∏´‡∏•‡∏ß‡∏°‡∏Ç‡∏∂‡πâ‡∏ô)
    aspect_ratio = detection.aspect_ratio
    aspect_diff = abs(aspect_ratio - 0.8)
    
    aspect_score = 0
    if aspect_diff < 0.15:   # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.1
        aspect_score = 100
    elif aspect_diff < 0.3:  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.2
        aspect_score = 85    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 80
    elif aspect_diff < 0.5:  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.3
        aspect_score = 70    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 60
    elif aspect_diff < 0.8:  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.5
        aspect_score = 55    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 40
    else:
        aspect_score = 35    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 20
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°
    final_score = (
        size_score * weights['size_weight'] / 100 +
        area_score * weights['area_weight'] / 100 +
        confidence_score * weights['confidence_weight'] / 100 +
        aspect_score * weights['aspect_weight'] / 100
    )
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° bonus score ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
    bonus_score = 5.0  # ‡πÄ‡∏û‡∏¥‡πà‡∏° 5 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
    final_score = min(final_score + bonus_score, 100.0)
    
    return final_score


def draw_detection_results(image: np.ndarray, detections: List[FaceDetection], 
                         show_quality: bool = True) -> np.ndarray:
    """
    ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏•‡∏á‡∏ö‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    
    Args:
        image: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        detections: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
        show_quality: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    
    Returns:
        ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß
    """
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    img_draw = image.copy()
    
    for face in detections:
        # ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        if show_quality and face.quality_score is not None:
            if face.quality_score >= 80:
                color = (0, 255, 0)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏°‡∏≤‡∏Å
            elif face.quality_score >= 60:
                color = (0, 255, 255)  # ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á = ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ
            elif face.quality_score >= 40:
                color = (0, 165, 255)  # ‡∏™‡πâ‡∏° = ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
            else:
                color = (0, 0, 255)  # ‡πÅ‡∏î‡∏á = ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥
        else:
            color = (0, 255, 0)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß (default)
        
        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö
        x1, y1, x2, y2 = int(face.bbox.x1), int(face.bbox.y1), int(face.bbox.x2), int(face.bbox.y2)
        cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, 2)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
        conf_text = f"{face.bbox.confidence:.2f}"
        cv2.putText(img_draw, conf_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
        if show_quality and face.quality_score is not None:
            quality_text = f"Q: {face.quality_score:.0f}"
            cv2.putText(img_draw, quality_text, (x1, y2 + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    return img_draw


def save_detection_image(image: np.ndarray, detections: List[FaceDetection], 
                        output_dir: str, filename: str) -> str:
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß
    
    Args:
        image: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        detections: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
        output_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
        filename: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        
    Returns:
        ‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    """
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    os.makedirs(output_dir, exist_ok=True)
    
    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    img_with_detections = draw_detection_results(image, detections, show_quality=True)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
    file_path = os.path.join(output_dir, filename)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
    cv2.imwrite(file_path, img_with_detections)
    
    return file_path


def validate_bounding_box(bbox: BoundingBox, image_shape: Tuple[int, int], min_size: int = 20, max_area_ratio: float = 0.95) -> bool: # MODIFIED: max_area_ratio to 0.95
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á bounding box - RELAXED VERSION
    
    Args:
        bbox: BoundingBox object ‡∏´‡∏£‡∏∑‡∏≠ dict
        image_shape: (height, width) ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    
    Returns:
        True ‡∏ñ‡πâ‡∏≤ bounding box ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á False ‡∏ñ‡πâ‡∏≤‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
    """
    try:
        # Extract coordinates
        if hasattr(bbox, 'x1'):
            x1, y1, x2, y2 = bbox.x1, bbox.y1, bbox.x2, bbox.y2
        else:
            x1 = bbox.get('x1', 0)
            y1 = bbox.get('y1', 0)
            x2 = bbox.get('x2', 0)
            y2 = bbox.get('y2', 0)
        
        img_height, img_width = image_shape[:2]
        
        # ===== ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏ß‡∏°‡∏Ç‡∏∂‡πâ‡∏ô =====
        
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î‡∏•‡∏ö
        if x1 < 0 or y1 < 0 or x2 < 0 or y2 < 0:
            logger.debug(f"‚ùå Negative coordinates: ({x1}, {y1}, {x2}, {y2})") # Changed to debug
            return False
        
        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡πÉ‡∏´‡πâ‡∏≠‡∏†‡∏±‡∏¢‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢)
        margin = 5  # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏≠‡∏ö 5 pixels
        if x2 > img_width + margin or y2 > img_height + margin:
            logger.debug(f"‚ö†Ô∏è Bbox slightly exceeds image bounds: ({x1}, {y1}, {x2}, {y2}) vs ({img_width}, {img_height})")
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö
            x2 = min(x2, img_width)
            y2 = min(y2, img_height)
        
        # 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö x2 > x1 ‡πÅ‡∏•‡∏∞ y2 > y1
        if x2 <= x1 or y2 <= y1:
            logger.debug(f"‚ùå Invalid bbox dimensions: width={x2-x1}, height={y2-y1}") # Changed to debug
            return False
        
        # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (‡∏•‡∏î‡∏•‡∏á‡∏°‡∏≤‡∏Å ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å)
        width = x2 - x1
        height = y2 - y1
        if width < 8 or height < 8:  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 12 ‡πÄ‡∏õ‡πá‡∏ô 8
            logger.debug(f"üîç Bbox very small: {width}x{height}")
            return False
          
        # 5. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û (‡∏´‡∏•‡∏ß‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å)
        bbox_area = width * height
        image_area = img_width * img_height
        area_ratio = bbox_area / image_area
        
        if area_ratio > 0.98:  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.95 ‡πÄ‡∏õ‡πá‡∏ô 0.98 (‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å)
            logger.debug(f"‚ö†Ô∏è Bbox covers large area: {area_ratio:.1%} - but allowing it")
            # ‡πÑ‡∏°‡πà return False ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏õ
        
        # 6. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö aspect ratio ‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏• (‡∏´‡∏•‡∏ß‡∏°‡∏°‡∏≤‡∏Å)
        aspect_ratio = width / height
        if aspect_ratio < 0.1 or aspect_ratio > 15.0:  # ‡∏´‡∏•‡∏ß‡∏°‡∏°‡∏≤‡∏Å ‡∏à‡∏≤‡∏Å 0.1-10.0 ‡πÄ‡∏õ‡πá‡∏ô 0.1-15.0
            logger.debug(f"üîç Unusual aspect ratio: {aspect_ratio:.2f} - but allowing it")
            # ‡πÑ‡∏°‡πà return False ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏õ
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Bbox validation failed: {e}")
        return False


def filter_detection_results(faces: list, image_shape: Tuple[int, int], 
                           min_quality: float = 30.0) -> list:  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 50.0 ‡πÄ‡∏õ‡πá‡∏ô 30.0
    """
    ‡∏Å‡∏£‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á - RELAXED VERSION
    
    Args:
        faces: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
        image_shape: (height, width) ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        min_quality: ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (‡∏•‡∏î‡∏•‡∏á)
    
    Returns:
        ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á
    """
    if not faces:
        return faces
    
    filtered_faces = []
    relaxed_validation_count = 0
    
    for face in faces:
        try:            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö bounding box
            if not validate_bounding_box(face.bbox, image_shape): # Uses relaxed validate_bounding_box
                logger.debug("üö´ Face filtered: invalid bbox")
                continue
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            if face.quality_score is None or face.quality_score > 100: # Uses relaxed calculate_face_quality
                face.quality_score = calculate_face_quality(face.bbox, image_shape)
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö‡∏´‡∏•‡∏ß‡∏°
            if face.quality_score >= min_quality:
                filtered_faces.append(face)
            else:
                # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥‡πÅ‡∏ï‡πà confidence ‡∏™‡∏π‡∏á ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ
                if hasattr(face.bbox, 'confidence') and face.bbox.confidence > 0.7:
                    logger.debug(f"üéØ Low quality but high confidence face accepted: "
                               f"quality={face.quality_score:.1f}, conf={face.bbox.confidence:.3f}")
                    filtered_faces.append(face)
                    relaxed_validation_count += 1
                else:
                    logger.debug(f"üö´ Face filtered: quality {face.quality_score:.1f} < {min_quality}")
                
        except Exception as e:
            logger.error(f"‚ùå Error filtering face: {e}")
            # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ (relaxed approach)
            logger.debug("üîÑ Adding face despite filtering error (relaxed mode)")
            filtered_faces.append(face)
            continue
    
    if relaxed_validation_count > 0:
        logger.info(f"üéØ Relaxed validation allowed {relaxed_validation_count} additional faces")
    
    logger.info(f"üéØ Filtered faces: {len(faces)} -> {len(filtered_faces)}")
    return filtered_faces
