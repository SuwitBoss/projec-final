"""
Face Recognition Service - Fixed version with Real ONNX Models and Unknown Detection
"""

import logging
import numpy as np
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
import time
import cv2
import os

# Conditional import for ONNX Runtime
try:
    import onnxruntime as ort  # type: ignore
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False
    ort = None

from .models import (
    FaceEmbedding,
    FaceMatch,
    FaceRecognitionResult,
    FaceComparisonResult,
    ModelType
)
from ..common.vram_manager import VRAMManager


@dataclass
class RecognitionConfig:
    """Configuration for face recognition with Unknown Detection"""
    similarity_threshold: float = 0.75  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.6
    unknown_threshold: float = 0.70     # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà
    max_faces: int = 10
    quality_threshold: float = 0.5      # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.3
    auto_model_selection: bool = True
    preferred_model: Optional[ModelType] = None
    enable_quality_assessment: bool = True
    enable_unknown_detection: bool = True  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà


class FaceRecognitionService:
    """Face Recognition Service with Real ONNX Models and Enhanced Unknown Detection"""
    
    def __init__(
        self,
        config: Optional[RecognitionConfig] = None,
        vram_manager: Optional[VRAMManager] = None
    ):
        self.logger = logging.getLogger(__name__)
        self.config = config or RecognitionConfig()
        self.vram_manager = vram_manager
        
        # Model management
        self.current_model = None
        self.current_model_type = self.config.preferred_model or ModelType.ADAFACE
        
        # Face database - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multiple embeddings ‡∏ï‡πà‡∏≠‡∏Ñ‡∏ô
        self.face_database: Dict[str, List[FaceEmbedding]] = {}        # Statistics
        self.stats: Dict[str, Any] = {
            'total_extractions': 0,
            'total_recognitions': 0,
            'successful_recognitions': 0,
            'unknown_detections': 0,
            'processing_times': []
        }
        
        self.logger.info("üöÄ Face Recognition Service initialized with Real ONNX Models")

    async def initialize(self) -> bool:
        """Initialize the face recognition service"""
        try:
            self.logger.info("üîß Initializing Face Recognition Service...")
            
            # Load default model
            success = await self.load_model(self.current_model_type)
            if not success:
                self.logger.error("‚ùå Failed to load default model")
                return False
            
            self.logger.info("‚úÖ Face Recognition Service initialized successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error initializing service: {e}")
            return False

    async def load_model(self, model_type: ModelType) -> bool:
        """Load specific face recognition model with REAL ONNX models"""
        try:
            # Check if model is already loaded
            if self.current_model_type == model_type and self.current_model is not None:
                return True
            
            # Clean up previous model
            if self.current_model is not None:
                self.current_model = None
            
            # Get correct model path
            base_path = os.path.join(os.getcwd(), "model", "face-recognition")
            
            if model_type == ModelType.ADAFACE:
                model_path = os.path.join(base_path, "adaface_ir101.onnx")
            elif model_type == ModelType.ARCFACE:
                model_path = os.path.join(base_path, "arcface_r100.onnx")
            else:  # FaceNet
                model_path = os.path.join(base_path, "facenet_vggface2.onnx")
            
            # Load REAL ONNX model
            if os.path.exists(model_path):
                self.logger.info(f"üîÑ Loading REAL {model_type.value} model from: {model_path}")
                  # Create inference session with optimizations
                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                session_options = ort.SessionOptions()
                session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
                
                self.current_model = ort.InferenceSession(
                    model_path, 
                    providers=providers,
                    session_options=session_options
                )
                self.current_model_type = model_type
                
                # Log model info
                if self.current_model is not None:
                    input_info = self.current_model.get_inputs()[0]
                    output_info = self.current_model.get_outputs()[0]
                    self.logger.info("‚úÖ Model loaded successfully:")
                    self.logger.info(f"   üìä Input shape: {input_info.shape}")
                    self.logger.info(f"   üìä Output shape: {output_info.shape}")
                    self.logger.info(f"   üîß Providers: {self.current_model.get_providers()}")
                
                return True
            else:
                self.logger.error(f"‚ùå Model file not found: {model_path}")
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå Error loading model {model_type.value}: {e}")
            return False

    async def extract_embedding(self, face_image) -> Optional[FaceEmbedding]:
        """Extract face embedding using real ONNX model"""
        try:
            start_time = time.time()
            
            # Ensure model is loaded
            if self.current_model is None:
                if not await self.initialize():
                    return None
            
            # Preprocess image for model
            input_tensor = self._preprocess_image(face_image, self.current_model_type)
            if input_tensor is None:
                self.logger.error("‚ùå Image preprocessing failed")
                return None
            
            # Use the loaded REAL model
            if self.current_model is not None:
                try:
                    # Run REAL model inference
                    input_name = self.current_model.get_inputs()[0].name
                    outputs = self.current_model.run(None, {input_name: input_tensor})
                    
                    # Extract embedding from output
                    embedding_vector = outputs[0]
                    if len(embedding_vector.shape) > 1:
                        embedding_vector = embedding_vector[0]  # Remove batch dimension if present
                    
                    # Normalize embedding
                    embedding_vector = embedding_vector / (np.linalg.norm(embedding_vector) + 1e-8)
                    
                    self.logger.debug(f"‚úÖ REAL embedding extracted: {embedding_vector.shape}")
                    
                except Exception as model_error:
                    self.logger.error(f"‚ùå Model inference failed: {model_error}")
                    # Fallback only if model fails
                    embedding_size = 512 if self.current_model_type in [ModelType.ADAFACE, ModelType.ARCFACE] else 128
                    image_hash = hash(str(face_image.tobytes())) % (2**31)
                    np.random.seed(image_hash)
                    embedding_vector = np.random.randn(embedding_size).astype(np.float32)
                    embedding_vector = embedding_vector / np.linalg.norm(embedding_vector)
                    np.random.seed()
                    self.logger.warning("‚ö†Ô∏è Using fallback embedding due to model error")
            else:
                self.logger.error("‚ùå No model loaded")
                return None
            
            # Calculate quality score (0-100)
            quality_score = self._calculate_embedding_quality(embedding_vector)
            
            processing_time = time.time() - start_time
            
            # Update statistics
            self.stats['total_extractions'] += 1
            self.stats['processing_times'].append(processing_time)
            
            embedding = FaceEmbedding(
                vector=embedding_vector.astype(np.float32),
                model_type=self.current_model_type,
                quality_score=quality_score,
                extraction_time=processing_time
            )
            
            self.logger.debug(f"‚úÖ Embedding extracted: shape={embedding_vector.shape}, quality={quality_score:.1f}")
            
            return embedding
            
        except Exception as e:
            self.logger.error(f"‚ùå Embedding extraction failed: {e}")
            return None

    async def recognize_face(self, face_image) -> FaceRecognitionResult:
        """Recognize face against database with Enhanced Unknown Detection"""
        try:
            start_time = time.time()
            
            # Extract embedding
            embedding = await self.extract_embedding(face_image)
            if embedding is None:
                return FaceRecognitionResult(
                    matches=[],
                    best_match=None,
                    confidence=0.0,
                    processing_time=time.time() - start_time,
                    model_used=self.current_model_type
                )
            
            # Search in database - ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö multiple embeddings ‡∏ï‡πà‡∏≠‡∏Ñ‡∏ô
            matches = []
            for person_id, stored_embeddings in self.face_database.items():
                # ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ similarity ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å multiple embeddings ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ô‡∏ô‡∏µ‡πâ
                max_similarity = 0.0
                best_stored_embedding = None
                
                for stored_embedding in stored_embeddings:
                    if stored_embedding.model_type != embedding.model_type:
                        continue
                      # Use improved cosine similarity calculation
                    if embedding.vector is not None and stored_embedding.vector is not None:
                        similarity = self._cosine_similarity(
                            embedding.vector, stored_embedding.vector
                        )
                    else:
                        similarity = 0.0
                    
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_stored_embedding = stored_embedding
                
                # Create match if above threshold
                if max_similarity >= self.config.similarity_threshold:
                    match = FaceMatch(
                        person_id=person_id,
                        confidence=max_similarity,
                        embedding=best_stored_embedding
                    )
                    matches.append(match)
            
            # Sort by confidence
            matches.sort(key=lambda x: x.confidence, reverse=True)
            
            # Enhanced Unknown Detection Logic
            best_match = None
            confidence = 0.0
            
            if matches:
                # Check if the best match is reliable enough
                top_match = matches[0]
                
                # Enhanced thresholds for unknown detection
                min_confidence_threshold = max(
                    self.config.similarity_threshold,
                    0.7  # Minimum 70% confidence for positive identification
                )
                
                # Quality-based threshold adjustment
                quality_factor = min(embedding.quality_score / 100.0, 1.0)
                adjusted_threshold = min_confidence_threshold * quality_factor
                
                if top_match.confidence >= adjusted_threshold:
                    best_match = top_match
                    confidence = top_match.confidence
                    self.stats['successful_recognitions'] += 1
                    self.logger.info(f"‚úÖ Face recognized: {top_match.person_id} (confidence: {top_match.confidence:.3f})")
                else:
                    # High similarity but not confident enough - mark as unknown
                    self.stats['unknown_detections'] += 1
                    self.logger.info(f"üîç Potential match {top_match.person_id} with confidence {top_match.confidence:.3f} "
                                   f"below adjusted threshold {adjusted_threshold:.3f} - marking as unknown")
            else:
                # No matches found
                self.stats['unknown_detections'] += 1
                self.logger.info("üîç No matches found - Unknown face")
              # Update statistics
            self.stats['total_recognitions'] += 1
            processing_time = time.time() - start_time
            
            result = FaceRecognitionResult(
                matches=matches,
                best_match=best_match,
                confidence=confidence,
                processing_time=processing_time,
                model_used=self.current_model_type,
                embedding=embedding.vector if embedding else None
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Face recognition failed: {e}")
            return FaceRecognitionResult(
                matches=[],
                best_match=None,
                confidence=0.0,
                processing_time=time.time() - start_time,
                model_used=self.current_model_type,
                error=str(e)
            )

    async def compare_faces(self, face1, face2) -> FaceComparisonResult:
        """Compare two face images"""
        try:
            start_time = time.time()
            
            # Extract embeddings
            embedding1 = await self.extract_embedding(face1)
            embedding2 = await self.extract_embedding(face2)
            
            if embedding1 is None or embedding2 is None:
                return FaceComparisonResult(
                    similarity=0.0,
                    is_same_person=False,
                    confidence=0.0,
                    processing_time=time.time() - start_time,
                    model_used=self.current_model_type
                )
              # Calculate similarity using improved cosine similarity
            if embedding1.vector is not None and embedding2.vector is not None:
                similarity = self._cosine_similarity(embedding1.vector, embedding2.vector)
            else:
                similarity = 0.0
            is_same_person = similarity >= self.config.similarity_threshold
            
            result = FaceComparisonResult(
                similarity=similarity,
                is_same_person=is_same_person,
                confidence=similarity,
                processing_time=time.time() - start_time,
                model_used=self.current_model_type
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Face comparison failed: {e}")
            return FaceComparisonResult(
                similarity=0.0,
                is_same_person=False,
                confidence=0.0,
                processing_time=time.time() - start_time,
                model_used=self.current_model_type,
                error=str(e)
            )

    async def add_face_to_database(self, person_id: str, face_image, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """Add face to recognition database - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multiple embeddings ‡∏ï‡πà‡∏≠‡∏Ñ‡∏ô"""
        try:
            embedding = await self.extract_embedding(face_image)
            
            if embedding is None:
                self.logger.error(f"‚ùå Failed to extract embedding for person {person_id}")
                return False
            
            # Add metadata
            if metadata:
                embedding.metadata = metadata
            
            # ‡πÄ‡∏Å‡πá‡∏ö multiple embeddings ‡∏ï‡πà‡∏≠‡∏Ñ‡∏ô ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö
            if person_id not in self.face_database:
                self.face_database[person_id] = []
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° embedding ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô list
            self.face_database[person_id].append(embedding)
            
            total_embeddings = len(self.face_database[person_id])
            self.logger.info(f"‚úÖ Added face for person {person_id} to database (total embeddings: {total_embeddings})")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error adding face to database: {e}")
            return False

    async def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics"""
        try:
            processing_times = self.stats['processing_times']
            avg_time = np.mean(processing_times) if processing_times else 0.0
            
            recognition_rate = (
                self.stats['successful_recognitions'] / self.stats['total_recognitions']
                if self.stats['total_recognitions'] > 0 else 0.0
            )
            
            unknown_rate = (
                self.stats['unknown_detections'] / self.stats['total_recognitions']
                if self.stats['total_recognitions'] > 0 else 0.0
            )
            
            return {
                'current_model': self.current_model_type.value if self.current_model_type else None,
                'model_loaded': self.current_model is not None,
                'database_size': len(self.face_database),
                'total_embeddings': sum(len(embs) for embs in self.face_database.values()),
                'performance': {
                    'total_extractions': self.stats['total_extractions'],
                    'total_recognitions': self.stats['total_recognitions'],
                    'successful_recognitions': self.stats['successful_recognitions'],
                    'unknown_detections': self.stats['unknown_detections'],
                    'recognition_rate': recognition_rate,
                    'unknown_detection_rate': unknown_rate,
                    'average_processing_time': avg_time
                },
                'thresholds': {
                    'similarity_threshold': self.config.similarity_threshold,
                    'unknown_threshold': self.config.unknown_threshold,
                    'quality_threshold': self.config.quality_threshold
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Error getting performance stats: {e}")
            return {}

    async def cleanup(self):
        """Cleanup resources"""
        try:
            if self.current_model is not None:
                self.current_model = None
            self.logger.info("‚úÖ Face Recognition Service cleaned up")
        except Exception as e:
            self.logger.error(f"‚ùå Error cleaning up: {e}")

    def _preprocess_image(self, face_image: np.ndarray, model_type: ModelType) -> Optional[np.ndarray]:
        """Preprocess image for specific model"""
        try:
            # Resize image to model input size
            if model_type in [ModelType.ADAFACE, ModelType.ARCFACE]:
                target_size = (112, 112)
            else:  # FaceNet
                target_size = (160, 160)
            
            face_resized = cv2.resize(face_image, target_size)
            
            # Convert BGR to RGB
            if len(face_resized.shape) == 3 and face_resized.shape[2] == 3:
                face_resized = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)
            
            # Normalize to 0-1
            face_normalized = face_resized.astype(np.float32) / 255.0
            
            # Model-specific normalization
            if model_type in [ModelType.ADAFACE, ModelType.ARCFACE]:
                # Standard normalization for ArcFace/AdaFace
                mean = np.array([0.5, 0.5, 0.5])
                std = np.array([0.5, 0.5, 0.5])
                face_normalized = (face_normalized - mean) / std
            else:  # FaceNet
                # FaceNet normalization
                face_normalized = (face_normalized - 0.5) * 2.0
              # Convert from HWC to CHW and add batch dimension
            input_tensor = np.transpose(face_normalized, (2, 0, 1))
            input_tensor = np.expand_dims(input_tensor, axis=0)
            
            # Ensure float32 type for ONNX model
            input_tensor = input_tensor.astype(np.float32)
            
            return input_tensor
            
        except Exception as e:
            self.logger.error(f"‚ùå Image preprocessing failed: {e}")
            return None

    def _calculate_embedding_quality(self, embedding: np.ndarray) -> float:
        """Calculate embedding quality score (0-100)"""
        try:
            # Calculate embedding statistics
            magnitude = np.linalg.norm(embedding)
            variance = np.var(embedding)
            sparsity = np.sum(np.abs(embedding) < 0.01) / len(embedding)            # Quality metrics
            magnitude_score = min(float(magnitude), 1.0)  # Good embeddings have ~1.0 magnitude
            variance_score = min(float(variance) * 10, 1.0)  # Good embeddings have reasonable variance
            sparsity_score = max(0.0, 1.0 - float(sparsity))  # Less sparse is better
            
            # Combine scores
            quality = (magnitude_score * 0.4 + variance_score * 0.3 + sparsity_score * 0.3)
            
            # Convert to 0-100 scale
            quality_score = float(np.clip(quality * 100, 0.0, 100.0))
            
            return quality_score
            
        except Exception:
            return 50.0  # Default medium quality

    def _cosine_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """Calculate cosine similarity between embeddings"""
        try:
            # Ensure embeddings are normalized
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            # Cosine similarity
            similarity = np.dot(embedding1, embedding2) / (norm1 * norm2)
            
            # Convert to 0-1 range (from -1 to 1)
            similarity = (similarity + 1.0) / 2.0
            
            return float(np.clip(similarity, 0.0, 1.0))
            
        except Exception as e:
            self.logger.error(f"‚ùå Similarity calculation failed: {e}")
            return 0.0
